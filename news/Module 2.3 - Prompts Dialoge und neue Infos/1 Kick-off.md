# Einführung in Prompt Engineering: Den LLMs neue Informationen beibringen

> [!tip] Alltag
> Stellen Sie sich vor, Sie bitten einen Freund, der noch nie von **Schach** gehört hat, eine Partie zu spielen. Ohne ihm die **Regeln** zu erklären und ihm zu zeigen, wie die **Figuren** bewegt werden, wird er nicht weit kommen. Genauso verhält es sich mit **LLMs (Large Language Models)**: Um **neue Informationen** zu verarbeiten und Aufgaben zu erledigen, benötigen sie klare Anweisungen und **relevante Daten** – und genau hier kommt **Prompt Engineering** ins Spiel.

> [!info]- Was ist möglich?
> - Sie können einem LLM beibringen, auf **aktuelle Ereignisse** zu reagieren, auch wenn sein Wissensstand begrenzt ist.
> - Sie können ein LLM nutzen, um **komplexe Sachverhalte** zu analysieren, indem Sie ihm gezielt **Informationen** liefern.
> - Sie können die **Grenzen von LLMs** besser verstehen und lernen, diese durch geschicktes Prompting zu überwinden.

>[!question]- Diskussion
>- Was sind die Herausforderungen, wenn man mit einem System interagiert, das nur über begrenztes Wissen verfügt?
>- Wie können wir sicherstellen, dass ein LLM **korrekte und relevante Informationen** erhält?
>- Welche Rolle spielt die **Verantwortung des Benutzers** beim Umgang mit LLMs?

> [!success]- Lernziele
> In dieser Einheit lernen wir, wie man **LLMs** durch **Prompt Engineering** mit neuen Informationen versorgt und sie so optimal für verschiedene Aufgaben einsetzt. 
> Das Ziel dieser Einheit ist, dass Sie...
> - verstehen, warum LLMs **zusätzliche Informationen** benötigen.
> - lernen, **effektive Prompts** zu erstellen, die LLMs mit den notwendigen Daten füttern.
> - die **Grenzen der Promptgrösse** erkennen und Strategien zur Informationsverdichtung anwenden können.

> [! question]- Wie weiter?
> - **LLMs** wie ChatGPT basieren auf **maschinellem Lernen** und werden mit riesigen Datenmengen **trainiert**.
> - Ihr **Wissensstand** ist jedoch auf den Zeitpunkt ihres letzten Trainings begrenzt.
> - Um **Informationen** zu verarbeiten, die über diesen Zeitpunkt hinausgehen oder nicht Teil ihres Trainingsdatensatzes waren, müssen wir sie im **Prompt** bereitstellen.
> -  **Prompts** sind **Texteingaben**, die dem LLM den Kontext und die Aufgabe vorgeben.
> -  Die **Qualität des Prompts** hat einen grossen Einfluss auf die **Genauigkeit und Relevanz** der Antworten des LLMs.
> -  **Prompt Engineering** befasst sich mit der Kunst, **effektive Prompts** zu erstellen, die LLMs zu optimalen Leistungen führen. 
